{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peripheral Arterial Disease\n",
    "\n",
    "## Project description\n",
    "\n",
    "A clinical research team is planning a retrospective study of peripheral arterial disease (PAD) to evaluate comorbidities (i.e., medical conditions that can occur along with PAD) and risk factors associated with PAD. An analyst is recruited to help build a cohort of patients with the disease. The research team requested that there are a few important variables that are indicative of a PAD diagnosis: explicit mention of a PAD diagnosis in a clinical note and specific values of a test called the Ankle Brachial Index (ABI) that are also recorded in notes. \n",
    "\n",
    "The task was to develop a system to identify positive mentions of PAD from each document in a set of clinical notes.\n",
    "\n",
    "Clinical context also has *temporality* and *experiencer* axes. However, peripheral arterial disease is a chronic condition that develops over time, therefore, it is never mentioned in hypotherical context (\\*\"if PAD develops...\"). It also never truly goes way, so if a patient had it befor, he/she still has the disease. Therefore, temporality axis always has value \"Current\". The disease also is never mentioned in relation to someone other than the patient, so the experiencer axis is always \"Patient\". Thus, the only context axis that matters is \"Negation\" with values of either  \"Affirmed\" or \"Negated\".\n",
    "\n",
    "The expected output is a comma-delimited file that would have the following columns:\n",
    "\n",
    "- patient identifier,\n",
    "- document identifier,\n",
    "- span starting index,\n",
    "- span ending index,\n",
    "- span snippet (the PAD mention string itself, e.g., \"peripheral artery disease\"),\n",
    "- affirmed/negated flag (e.g., an affirmative example: \"Mr. Jones has periperhal artery disease.\" so flag should indicate an affirmed mention; a negative example: \"Tests indicate no PAD present.\" so flag should indicate this is a false mention of PAD),\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following notebooks outline the steps required to perform the project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create reference standard\n",
    "\n",
    "NLP system development requires manual annotation. [Classification_prep.ipynb](Classification_prep.ipynb) outlines the steps to create document sets for training and testing a system. \n",
    "Splitting the set into training and testing can be done either before annotation or after. The example in Classification_prep notebook shows splitting the set before manual annotaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implement the system\n",
    "\n",
    "TThe task here falls into the category of \"mention classification tasks\" which have the following general steps:\n",
    "- Identifying the concept\n",
    "- Building context window\n",
    "- Classifying the concept based on context\n",
    "\n",
    "The same general design can be implemented in multiple ways.\n",
    "\n",
    "- [Simple_Classification_System.ipynb](Simple_Classification_System.ipynb)  -- uses regular expressions to find mentions of the target concept and checks for negative modifiers up to 30 characters before the target mention.\n",
    "\n",
    "**Will be shared by request with point penalty**:\n",
    "- [Classification_Rule_Based.ipynb](Classification_Rule_Based.ipynb) -- uses the system built in Module 5 with a slight modification using the [wrapperPyConText](wrapperPyConText_doc.html).convertMarkupsAnnotations function to convert PyConText annotations to [pipeUtils](pipeUtils_doc.html).Document annotations.\n",
    "\n",
    "- [Classification_System.ipynb](Classification_System.ipynb) -- uses [wrapperPyConText](wrapperPyConText_doc.html) to encapsulate pyConTextNLP code and adapts it to the framework defined in pipeUtils."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Validate the System\n",
    "\n",
    "[Simple_Classification_System.ipynb](Simple_Classification_System.ipynb)  notebook defines the code to read the test files using the functionality in pipeUtils framework, apply the NLP system on the documents, and produce efficacy metrics for each document and aggregate for the whole set.\n",
    "\n",
    "\n",
    "## 4 Deploy the system\n",
    "\n",
    "MIMIC II contains a small enough dataset that can be processed at once. [Simple_Classification_System.ipynb](Simple_Classification_System.ipynb) notebook shows how to output the results of the classification system by writing them to a csv file. The easiest way to output is using Pandas dataframe to_csv method. The dataframe and the output file can be evaluated to determine the total number of records produced by the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
