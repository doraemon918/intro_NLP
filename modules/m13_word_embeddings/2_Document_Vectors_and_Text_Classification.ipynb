{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for this notebook:\n",
    "1. Internet connection (to download corpora and tokenizer data with calls to nltk.download())\n",
    "2. The following packages:\n",
    "  1. nltk (Anaconda or PIP command line install : pip install -U nltk OR conda install nltk)\n",
    "  2. gensim (pip install -U gensim)\n",
    "  3. scikit-learn v0.18.1 (pip install -U scikit-learn)\n",
    "  4. matplotlib (pip install -U matplotlib)\n",
    "  5. numpy (pip install -U numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives of this notebook are to illustrate how we can do the following with word embeddings:\n",
    "1. Introduce Document Vectors (Doc2Vec)\n",
    "2. Compare sentence vectors\n",
    "3. Use these for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, so having a vector to represent a sequence of words (sentence, paragraph or document) would be useful, but how does it work?  \n",
    "## It's very similar to word2vec.  Word2vec predicts a word based on its neighbors or neighbors based on a word.  Doc2Vec is extremely similar but it adds the concept of a \"Document ID\" which can represent any sequence of text (sentence, paragraph or document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Brief Description of Dov2Vec](doc2vec.png)\n",
    "\n",
    "Le, Q., & Mikolov, T. (2014, January). Distributed representations of sentences and documents. In International Conference on Machine Learning (pp. 1188-1196)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import nltk\n",
    "nltk.__version__\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.14.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sklearn.__version__\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\slick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "Wall time: 1.72 s\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\slick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Wall time: 156 ms\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\slick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "Wall time: 82.9 ms\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\slick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Wall time: 63.1 ms\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\slick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Wall time: 3.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download our corpora\n",
    "%time nltk.download('brown')\n",
    "%time nltk.download('movie_reviews')\n",
    "%time nltk.download('treebank')\n",
    "# Let's download the PUNKT tokenizer first so that we can use tokenize words and sentences\n",
    "%time nltk.download('punkt')\n",
    "# Let's download stopwords so we can plot them later\n",
    "%time nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.']\n",
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "print(brown.sents()[0])\n",
    "print(movie_reviews.sents()[0])\n",
    "print(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pro Tip : These corpora are relatively small.  We may not get great results.  Certainly not as large as GoogleNews, Wikipedia, PubMed, etc.  Our mileage may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown sentence count :  57340\n",
      "Movie Review sentence count :  71532\n",
      "Treebank sentence count :  3914\n"
     ]
    }
   ],
   "source": [
    "# How many sentences do we have in each corpus?\n",
    "print('Brown sentence count : ', len(brown.sents()))\n",
    "print('Movie Review sentence count : ', len(movie_reviews.sents()))\n",
    "print('Treebank sentence count : ', len(treebank.sents()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's determine what parameters we will use for the doc2vec training\n",
    "D2V_SKIP_GRAM = 0\n",
    "D2V_DIMENSIONS = 100\n",
    "D2V_MIN_COUNT = 3\n",
    "# How many worker threads should we use to train?  Depends on your hardware...\n",
    "D2V_WORKERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's do something slightly different and set up a document-level Doc2Vec model and use this for classification (also using Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PRO TIP : This is a generator class (notice the __iter__() and the yield)\n",
    "# This makes setting up a \"LabeledSentence\" class much easier and it becomes almost essential when training large \n",
    "# models for either Word2Vec or Doc2Vec since some corpora are so large that we cannot keep them in memory while training\n",
    "# the vector model.  Therefore, you can \"iterate\" through files or database rows and only keep batches of them \n",
    "# in memory at a time\n",
    "class TaggedNltkSentence(object):\n",
    "    def __init__(self, nltk_corpus, max_training_documents = -1):\n",
    "        self.nltk_corpus = nltk_corpus\n",
    "        self.max_training_documents = max_training_documents\n",
    "    def __iter__(self):\n",
    "        sent_idx = 0\n",
    "        sentences = self.nltk_corpus.sents()\n",
    "        \n",
    "        if self.max_training_documents > 0:\n",
    "            sentence_count_before = len(sentences)\n",
    "            sentences = sentences[:self.max_training_documents]\n",
    "            print('Using a smaller training set.  Reducing from size : {0} to {1}'.format(sentence_count_before, len(sentences)))\n",
    "            \n",
    "        for sent in sentences:\n",
    "            sent_idx += 1\n",
    "            # NOTE : These tags are not actually used during training time, but they are used\n",
    "            # to index and potentially query to find similar sentences/paragraphs/documents in GenSim\n",
    "            yield TaggedDocument(words=sent, tags=['SENT_%s' % sent_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Doc2Vec model.  This can take some time...\n",
      "Done training Doc2Vec model.\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "print('Training a Doc2Vec model.  This can take some time...')\n",
    "movie_d2v_model = Doc2Vec(TaggedNltkSentence(movie_reviews), \n",
    "                                size = D2V_DIMENSIONS, \n",
    "                                min_count = D2V_MIN_COUNT, \n",
    "                                workers = D2V_WORKERS)\n",
    "\n",
    "print('Done training Doc2Vec model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have a model, let's try it out by comparing some sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n",
      "[[0.76293653]] similarity score comparing [I loved this great movie] to [I loved this fantastic film]\n",
      "*************\n",
      "[[0.37942412]] similarity score comparing [I loved this great movie] to [boring and terrible]\n",
      "*************\n",
      "[[0.76293653]] similarity score comparing [I loved this fantastic film] to [I loved this great movie]\n",
      "*************\n",
      "[[0.35001126]] similarity score comparing [I loved this fantastic film] to [boring and terrible]\n",
      "*************\n",
      "[[0.37942412]] similarity score comparing [boring and terrible] to [I loved this great movie]\n",
      "*************\n",
      "[[0.35001126]] similarity score comparing [boring and terrible] to [I loved this fantastic film]\n",
      "DONE comparing sentences\n"
     ]
    }
   ],
   "source": [
    "# In this example, the average embeddings vectors for sentence_1 and sentence_2 would be the same\n",
    "# However, doc2vec sees them as different.  This will allow context to be handled differently and a classifier\n",
    "# will be able to learn about these differences\n",
    "\n",
    "sentence_1 = 'I loved this great movie'\n",
    "sentence_2 = 'I loved this fantastic film'\n",
    "sentence_3 = 'boring and terrible'\n",
    "sentence_texts = [sentence_1, sentence_2, sentence_3]\n",
    "\n",
    "sentence_vectors = []\n",
    "for sentence_text in sentence_texts:\n",
    "    sentence_vec = movie_d2v_model.infer_vector(nltk.tokenize.word_tokenize(sentence_text))\n",
    "    sentence_vec = sentence_vec.reshape(1, -1)\n",
    "    sentence_vectors.append(sentence_vec)\n",
    "\n",
    "for i in range(len(sentence_vectors)):\n",
    "    for j in range(len(sentence_vectors)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print('*************')\n",
    "        print('{0} similarity score comparing [{1}] to [{2}]'.format(\n",
    "             sklearn.metrics.pairwise.cosine_similarity(sentence_vectors[i], sentence_vectors[j]),\n",
    "             sentence_texts[i],\n",
    "             sentence_texts[j]))\n",
    "\n",
    "print('DONE comparing sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's try to visualize some of the embeddings vectors with reduced dimensions (by way of t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8oAAAIXCAYAAABEuKdxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSepxoSxJkiRJUs//ZZ+eJJ8TXsEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2970447da58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_sentences(d2v_model, target_sentences):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    sentence_vectors = []\n",
    "    # let's make sure that a term we want is in the model\n",
    "    for target_sentence in target_sentences:\n",
    "        document_tokens = target_sentence.split()\n",
    "        sentence_vector = d2v_model.infer_vector(document_tokens)\n",
    "        sentence_vectors.append(sentence_vector)\n",
    "    Y = tsne.fit_transform(sentence_vectors)\n",
    "    \n",
    "    # let's make this plot a decent size...\n",
    "    # Get current size\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    # Set figure width and height\n",
    "    fig_size[0] = 15\n",
    "    fig_size[1] = 9\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    " \n",
    "    plt.scatter(Y[:, 0], Y[:, 1])\n",
    "    for label, x, y in zip(target_sentences, Y[:, 0], Y[:, 1]):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.show()\n",
    "    \n",
    "target_plot_sentences = ['I absolutely adored the movie', 'I loved it more than any other movie', 'I hated it']\n",
    "plot_sentences(movie_d2v_model, target_plot_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's get ready to use these sentence vectors in a text classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Doc2VecVectorizer(object):\n",
    "    def __init__(self, d2v_model):\n",
    "        self.d2v_model = d2v_model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # NOTE : infer_vector can take a list of strings (words) of arbitrary lenghth and infer a vector\n",
    "        # given its model parameters\n",
    "        return [self.d2v_model.infer_vector(doc) for doc in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN set size : 1600\n",
      "TEST set size : 400\n"
     ]
    }
   ],
   "source": [
    "X = [movie_reviews.words(fileid) for fileid in movie_reviews.fileids()]\n",
    "# these are the categories\n",
    "y_categories = [movie_reviews.categories(fileid)[0] for fileid in movie_reviews.fileids()]\n",
    "# this maps the strings to 1 -> positive 0 -> negative (anything else)\n",
    "y = [1 if category == 'pos' else 0 for category in y_categories ]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 777)\n",
    "\n",
    "print('TRAIN set size : {}'.format(len(X_train)))\n",
    "print('TEST set size : {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's transform all of our sentences into vectors to use them in text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN transformed vector size : 1600\n",
      "TEST transformed vector size : 400\n",
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_vectors = [movie_d2v_model.infer_vector(doc) for doc in X_train]\n",
    "X_test_vectors = [movie_d2v_model.infer_vector(doc) for doc in X_test]\n",
    "\n",
    "print('TRAIN transformed vector size : {}'.format(len(X_train_vectors)))\n",
    "print('TEST transformed vector size : {}'.format(len(X_test_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...  this could take some time\n",
      "Doc2Vec F1 : 0.7142857142857143\n",
      "Wall time: 88.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Training the model...  this could take some time')\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vectors, y_train)\n",
    "\n",
    "d2v_f1 = f1_score(y_test, lr.predict(X_test_vectors))\n",
    "print('Doc2Vec F1 : {}'.format(d2v_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As one more experiment, let's examine the impact of how many documents we use to train the unsupervised Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a smaller Doc2Vec model.  This can take some time...\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Using a smaller training set.  Reducing from size : 71532\n",
      "To a training size of : 500\n",
      "Done training Doc2Vec model.\n",
      "Wall time: 47.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "SMALL_DOCUMENT_COUNT = 500\n",
    "\n",
    "print('Training a smaller Doc2Vec model.  This can take some time...')\n",
    "movie_d2v_model_small = Doc2Vec(TaggedNltkSentence(movie_reviews, max_training_documents = SMALL_DOCUMENT_COUNT), \n",
    "                                size = D2V_DIMENSIONS, \n",
    "                                min_count = D2V_MIN_COUNT, \n",
    "                                workers = D2V_WORKERS)\n",
    "\n",
    "print('Done training Doc2Vec model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN smaller transformed vector size : 1600\n",
      "TEST smaller transformed vector size : 400\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train_vectors_small = [movie_d2v_model_small.infer_vector(doc) for doc in X_train]\n",
    "X_test_vectors_small = [movie_d2v_model_small.infer_vector(doc) for doc in X_test]\n",
    "\n",
    "print('TRAIN smaller transformed vector size : {}'.format(len(X_train_vectors)))\n",
    "print('TEST smaller transformed vector size : {}'.format(len(X_test_vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the smaller model...  this could take some time\n",
      "Doc2Vec (smaller training size) F1 : 0.517766497461929\n",
      "Wall time: 20.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Training the smaller model...  this could take some time')\n",
    "lr_small = LogisticRegression()\n",
    "lr_small.fit(X_train_vectors_small, y_train)\n",
    "\n",
    "d2v_f1_small = f1_score(y_test, lr_small.predict(X_test_vectors_small))\n",
    "print('Doc2Vec (smaller training size) F1 : {}'.format(d2v_f1_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
